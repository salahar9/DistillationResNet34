{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":459489,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":372382,"modelId":393260}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install detectors -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch,timm,detectors\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torch.nn import KLDivLoss\ntransform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n                         std=[0.2023, 0.1994, 0.2010])\n])\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=128 , shuffle=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nteacher_model = timm.create_model(\"resnet34_cifar10\", pretrained=True).to(device)\nteacher_model.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the StudentCNN model\nclass StudentCNN(nn.Module):\n    def __init__(self):\n        super(StudentCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # Adjusted for CIFAR-10\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_kl_and_ce(student_model, teacher_model, loader, optimizer,scheduler, epochs=150, temperature=4, alpha=0.7):\n    kl_loss = nn.KLDivLoss(reduction='batchmean')\n    ce_loss = nn.CrossEntropyLoss()\n    student_model.train()\n\n    for epoch in range(epochs):\n        total_loss = 0\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n\n            with torch.no_grad():\n                teacher_logits = teacher_model(images)\n                teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n\n            optimizer.zero_grad()\n            student_logits = student_model(images)\n\n            # KL Divergence Loss\n            student_log_probs = F.log_softmax(student_logits / temperature, dim=1)\n            loss_kl = kl_loss(student_log_probs, teacher_probs) * (temperature ** 2)\n\n            # Cross-Entropy Loss\n            loss_ce = ce_loss(student_logits, labels)\n\n            # Combined Loss\n            loss = alpha * loss_kl + (1 - alpha) * loss_ce\n\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        scheduler.step()\n\n        print(f\"Epoch {epoch+1}, Total Loss: {total_loss:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"student_model_kl = StudentCNN()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nstudent_model_kl.to(device)\noptimizer_kl = torch.optim.SGD(\n    student_model.parameters(),\n    lr=0.1,              # initial learning rate\n    momentum=0.9,\n    weight_decay=5e-4\n)\n\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=epochs  # total number of epochs\n)\n\ntrain_with_kl_and_ce(student_model_kl, teacher_model, train_loader, optimizer_kl,scheduler)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(student_model_kl, '/kaggle/working/model.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correct = 0\ntotal = 0\ntest_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=128 , shuffle=False)\nwith torch.no_grad():\n    for images, labels in test_loader:\n        outputs = student_model_kl(images.to(device))\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels.to(device)).sum().item()\n\naccuracy = 100 * correct / total\nprint(f'Test Accuracy: {accuracy:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}